---
title: "Efficacy in Financial Rulemaking"
#subtitle: "Appendix and Replication Code"
output:
    bookdown::html_document2:
      highlight: zenburn
      toc: true
      toc_float: true
      code_folding: hide
      number_sections: false
---



```{r options, include=FALSE}
# rmarkdown::render("docs/efficacy.Rmd")
source(here::here("code", "setup.R"))

## Change defaults for R chunks
knitr::opts_chunk$set(#echo = FALSE, # echo = TRUE means that code will show
                      cache = FALSE,
                      fig.path = "../figs/", # figs folder at root (up one from /docs),
                      #fig.retina = 3, #6, #FIXME for publication-quality images
                      fig.height=2.3, 
                      fig.width=3.2, 
                      out.width="50%")

```


# Data

The root for this script is `finreg`. Most of the data are in `finreg/data` (some in a subfolder `merged_resources`). Others are up one level in `FINREGRULEMAKE2/Data`. This can and should be streamlined significantly. 


## Sophistication 


File: `Data/Dictionary_Terms.RData` contains six objects (3 sets of measures for both comments and attachments)

### 1. Dictionary counts of technical terms used in comments and attachments

We use the [Oxford Dictionary of Finance and Banking](https://www.oxfordreference.com/view/10.1093/acref/9780199664931.001.0001/acref-9780199664931) and the [Merriam Webster law dictionary](https://www.merriam-webster.com/browse/legal/). While Black's is a more common law dictionary, a complete version is not available online.


Objects: `technical_terms_comments` and `technical_terms_attachment`

Variables:

- `doc_id` - the comment_url or attachment_url in the comments and attachments files in master.sqlite
- `uk_law` - UK law terms - this is in the file as I was curious how many of the terms would be in a UK law dictionary.
- `banking` - US banking terms in Merriam Webster's banking dictionary
- `us_law` - US law terms in Merriam Webster's US law dictionary. We didn't use Black's law dictionary because it's incomplete, as shown at the beginning of the `dictionary_and_bluebook.R` file
- `overlap` - terms in both banking and us_law
- `dictionary_term`s - banking + us_law - overlap
- `Comment` - 1 if from the comments file in Master, 0 if from attachments

### 2. Tables and Figures

Counts of Tables and Figures. Looks at the maximum number of tables, with large jumps excluded. For example, a document with tables 1, 2, 3, and 99 would treat 99 as an error and say there were three tables. This mostly comes from bad OCRing or documents that have footnotes in between the word "table" and the table number.

Objects: `Tables_and_Figures_attachments` and `Tables_and_Figures_comments`

Variables:

- `comment_url` - the comment_url or attachment_url in the comments and attachments files in master.SQLite
- `Figures` - counts of figures
- `Tables`- counts of tables
- `Comment` - 1 if from comments, 0 if from attachments
- `Visualizations` - sum of figures + tables

### 3. Bluebook legal citations

Counts of citations to US code, Supreme Court cases, appellate and district court cases, the code of federal regulations, and the federal register

Objects: `bluebok_comments` and `bluebook_attachments`

Variables:

- `Comment` - 1 if from comments, 0 if from attachments
- `comment_url` - the comment_url or attachment_url in the comments and attachments files in master.SQLite
- `US_Code` - counts of US code citations
- `Supreme_Court_Cases` - counts of Supreme Court cases
- `Appeals_and_District_Court_Cases` - counts of citations to Appeals and district court cases
- `Code_of_Federal_Regulations` - counts of citations to CFR
- `Federal_Register_Total` - counts of citations to the federal register
- `Total_Legal_Citations` - the sum of the above except comment dummy


```{r sophistication}
# sophistication 
load(here("data", "Dictionary_Terms.Rdata")  %>% str_remove("finreg")  )

# drop duplicates 
technical_terms_comments %<>% 
  distinct() 

technical_terms_attachments %<>% 
  distinct() 

bluebook_comments %<>% 
  distinct() 

bluebook_attachments %<>% 
  distinct()  
```


```{r sophistication-join}
# summarize and merge term counts from comment text boxes and attachments
# max <- . %>% base::max(na.rm = TRUE)


# sum by comment URL 
#FIXME, why are these not unique! 
bluebook_c <- bluebook_comments %>% 
  drop_na(Total_Legal_Citations) %>% 
  group_by(comment_url) %>% 
  dplyr::select(-comment) %>% 
  summarise_all(base::max)

# whereas these should not be unique to comment URL 
bluebook_a <- bluebook_attachments %>% 
  drop_na(Total_Legal_Citations) %>% 
  group_by(comment_url) %>% 
  dplyr::select(-comment) %>% 
  summarise_all(base::max)

# join both and max again 
bluebook <- full_join(bluebook_a,
                      bluebook_c) %>% 
  group_by(comment_url) %>% 
  summarise_all(base::max)

# # check for unique comment_url
# bluebook %>% count(comment_url, sort = T)

# sum by comment URL 
#FIXME, why are these not unique!? 
technical_terms_c <- technical_terms_comments %>% 
  drop_na(dictionary_terms) %>% 
  group_by(comment_url) %>% 
  dplyr::select(-comment) %>% 
  summarise_all(base::max)

# whereas these should not be unique to comment URL 
technical_terms_a <- technical_terms_attachments %>% 
  drop_na(dictionary_terms) %>% 
  group_by(comment_url) %>% 
  dplyr::select(-comment) %>% 
  summarise_all(base::max)

# join both and sum again 
technical_terms <- full_join(technical_terms_a,
                             technical_terms_c) %>% 
  group_by(comment_url) %>% 
  summarise_all(base::max)

# # check for unique comment_url
# technical_terms %>% count(comment_url, sort = T)

full_join(technical_terms, bluebook) %>% kablebox()

# check that they are the same 
# full_join(bluebook, technical_terms)
```

---

## Assets 

- see https://judgelord.github.io/finreg/participation

```{r asset-data}
load(here::here("data", "commenter_assets.Rdata"))

d <- commenter_assets

#FIXME MOVE TO TOP 
d$comment_url %<>% str_replace("document\\?D=", "comment/")


d %>% arrange(assets) %>% 
  dplyr::select(org_name, assets, revenue, comment_url) %>% kablebox()

d %>% arrange(marketcap2) %>% 
  dplyr::select(org_name, marketcap, comment_url) %>% kablebox()

d %>% arrange(-MeanContribAmount) %>% 
  dplyr::select(org_name, MeanContribAmount, comment_url) %>% kablebox()
```

---

## Efficacy

File: `Data/attachment_efficacy_w_docket.csv.`

Variables: 

- `efficacy` = `cumulative_sequence_length_over_10`

Other efficacy measures that we are not using: 

- number_of_other_sequences_over_10
- number_of_other_sequences_over_25
- number_of_other_sequences_over_50
- number_of_other_sequences_over_100
- cumulative_sequence_length_over_10
- cumulative_sequence_length_over_25
- cumulative_sequence_length_over_50
- cumulative_sequence_length_over_100
- longest_sequence_length
- longest_repeated_text

```{r efficacy}
# efficacy
efficacy_raw <- read_csv( here::here("data", "new_attachment_efficacy_w_docket.csv")  %>% str_remove("finreg")  )

# inspect 
# efficacy_raw %>% distinct() %>% dplyr::select(attachment_url, fr_document_id_final) %>% add_count(attachment_url) %>% arrange(-n) %>%   kablebox()

# # look for non-numeric values other than headers
# efficacy_raw %>% 
#   filter(!is.na(cumulative_sequence_length_over_10),
#          comment_url != "comment_url") %>% 
#   mutate(efficacy = cumulative_sequence_length_over_10 %>% as.numeric() ) %>% 
#   filter(is.na(efficacy)) %>% 
#   dplyr::select(comment_url, cumulative_sequence_length_over_10)

# select needed vars. URL is comment URL (even for attachments)
efficacy <- efficacy_raw %>% 
  # make comment URL 
  mutate(comment_url2 = attachment_url %>% 
           str_replace("https://downloads.regulations.gov/", 
                       "https://www.regulations.gov/comment/" ) %>% 
           str_remove("/attachment_.*"),
         comment_url = coalesce(comment_url, comment_url2),
         efficacy = cumulative_sequence_length_over_10 %>% as.numeric()
         ) %>% 
  dplyr::select(comment_url,
         efficacy) %>% 
  distinct() 

# check for OCC comments (missing as of May 2022)
# efficacy %>% filter(str_detect(comment_url, "OCC"))

# check for CFPB comments (not missing, but failing to merge with d on URL?)
# efficacy %>% filter(str_detect(comment_url, "CFPB"))



efficacy %<>% drop_na(efficacy) 


# take max
efficacy %<>% 
  group_by(comment_url) %>% 
  summarise_all(base::max)

efficacy %>% arrange(-efficacy) %>% kablebox()

# d$comment_url %in% efficacy$comment_url %>% sum

# efficacy$comment_url %in% d$comment_url %>% sum

#efficacy %>% filter(str_detect(comment_url, "CFPB")) %>%  kablebox()

d  %<>% left_join(efficacy) 

d %>% group_by(Agency) %>% count(is.na(efficacy))
```



```{r testing, eval = FALSE}
# check the number of NAS 
bluebook_comments %>%
  summarise_all(is.na) %>%
  summarise_all(sum)

# multiple per URL? 
bluebook_comments %>%  count(comment_url, sort = T)

bluebook_attachments %>%  count(comment_url, sort = T)

# example
bluebook_attachments %>% filter(comment_url == "https://www.regulations.gov/comment/OCC-2011-0008-0126") %>% kablebox()

bluebook_comments %>% filter(comment_url == "https://www.regulations.gov/comment/OCC-2011-0008-0126") %>% kablebox()

technical_terms_comments %>% count(comment_url, sort = T)

technical_terms_attachments %>% count(comment_url, sort = T)
```

---

### Join sophistication and asset data

```{r sophistication-assets-join, fig.height=3.5, fig.width=4}
# Join 
d %<>% 
  left_join(bluebook %>% dplyr::select(comment_url, Total_Legal_Citations)) %>% 
  left_join(technical_terms %>% dplyr::select(comment_url, dictionary_terms)) 

d %>% 
  dplyr::select(comment_url, org_name, Total_Legal_Citations, dictionary_terms, assets, marketcap, MeanContribAmount) %>% 
  filter(!is.na(dictionary_terms)) %>% 
  kablebox()

# write out missing comment URLs
d %>% 
  filter(is.na(dictionary_terms)) %>% dplyr::select(comment_url) %>% write_csv(file = "dictionary_terms_missing.csv")

# FIXME Missing as of May 2022
# bluebook %>% filter(str_detect(comment_url, "CFPB-2019-0021-0406"))
# technical_terms %>% filter(str_detect(comment_url, "CFPB-2019-0021-0406"))


#FIXME DROP BAD EFFICACY COMMENTS
efficacy%<>% filter(!comment_url %in% c(
  "https://comments.cftc.gov/Handlers/PdfHandler.ashx?id=23750",
  "https://www.regulations.gov/comment/CFPB-2012-0029-0054"
))


# look for outliers 
efficacy %>% arrange(-efficacy) %>% kablebox(
)

technical_terms %>% 
      dplyr::select(comment_url, dictionary_terms) %>% 
  arrange(-dictionary_terms) %>% kablebox()

#FIXME DROP BAD TECHNICAL TERM MEASURE 
technical_terms %<>% filter(!comment_url %in% c(
  "https://www.regulations.gov/comment/OCC-2013-0008-0028"
))

#FIXME DROP BAD TECHNICAL TERM MEASURE 
technical_terms %<>% filter(!comment_url %in% c(
  "https://www.regulations.gov/comment/OCC-2013-0008-0028"
))

bluebook %>% 
      dplyr::select(comment_url, Total_Legal_Citations) %>% 
  arrange(-Total_Legal_Citations) %>% kablebox()
  
efficacyXsophistication <- bluebook %>% 
  dplyr::select(comment_url, Total_Legal_Citations) %>% drop_na(Total_Legal_Citations) %>% 
  left_join(
    technical_terms %>% 
      dplyr::select(comment_url, dictionary_terms)
  ) %>% 
  left_join(efficacy) %>% 
  mutate(efficacy = replace_na(efficacy, 0),
         org = ifelse(comment_url %in% d$comment_url, "Matched organization", "Individual or\nunmatched organization") )
```

### Matched vs. unmatched comments

```{r matched-by-terms, fig.height=3.5, fig.width=5}
# matched-by-terms

efficacyXsophistication %>% 
  ggplot() + 
  aes(x = dictionary_terms, fill = org) +
  geom_histogram() + 
  facet_wrap("org", ncol = 1, scales = "free_y") + 
  scale_y_log10() + 
  labs(title = str_c("Comments on Dodd-Frank Rules, N = ", nrow(efficacyXsophistication) %>% prettyNum(big.mark = ",")),
       y = "Number of Comments",
       x = "Technical Terms in Comment",
       fill = "") 

efficacyXsophistication %>% 
  ggplot() + 
  aes(x = dictionary_terms, fill = org) +
  geom_density(alpha = .5, color = NA) + 
  #facet_wrap("org", ncol = 1, scales = "free_y") + 
  scale_x_log10() + 
  labs(title = str_c("Comments on Dodd-Frank Rules, N = ", nrow(efficacyXsophistication) %>% prettyNum(big.mark = ",")),
       y = "",
       x = "Technical Terms in Comment",
       fill = "") 

```



```{r matched-by-bluebook, fig.height=3.5, fig.width=5}
#  matched-by-bluebook

efficacyXsophistication %>% 
  ggplot() + 
  aes(x = Total_Legal_Citations, fill = org) +
  geom_histogram() + 
  facet_wrap("org", ncol = 1, scales = "free_y") + 
  scale_y_log10() + 
  labs(title = str_c("Comments on Dodd-Frank Rules, N = ", nrow(efficacyXsophistication) %>% prettyNum(big.mark = ",")),
       y = "Number of Comments",
       x = "Legal Citations in Comment",
       fill = "") 

efficacyXsophistication %>% 
  ggplot() + 
  aes(x = Total_Legal_Citations, fill = org) +
  geom_density(alpha = .5, color = NA) + 
  #facet_wrap("org", ncol = 1, scales = "free_y") + 
  scale_x_log10() + 
  labs(title = str_c("Comments on Dodd-Frank Rules, N = ", nrow(efficacyXsophistication) %>% prettyNum(big.mark = ",")),
       y = "",
       x = "Legal Citations in Comment",
       fill = "") 
```

```{r matched-by-efficacy, fig.height=3.5, fig.width=5}
# matched-by-efficacy

efficacyXsophistication %>% 
  ggplot() + 
  aes(x = efficacy, fill = org) +
  geom_histogram() + 
  facet_wrap("org", ncol = 1, scales = "free_y") + 
  scale_y_log10() + 
  labs(title = str_c("Comments on Dodd-Frank Rules, N = ", nrow(efficacyXsophistication) %>% prettyNum(big.mark = ",")),
       y = "Number of Comments",
       x = "Lobbying Success\nn(Words From Comment\nAdded to Final Rule)",
       fill = "") 

efficacyXsophistication %>% 
  ggplot() + 
  aes(x = efficacy, fill = org) +
  geom_density(alpha = .5, color = NA) + 
  #facet_wrap("org", ncol = 1, scales = "free_y") + 
  scale_x_log10() + 
  labs(title = str_c("Comments on Dodd-Frank Rules, N = ", nrow(efficacyXsophistication) %>% prettyNum(big.mark = ",")),
       y = "Number of Comments",
       x = "Lobbying Success\nn(Words From Comment\nAdded to Final Rule)",
       fill = "") 
```

### Efficacy by Sophistication 


```{r efficacyXsophistication, fig.height=3.5, fig.width=5}
# efficacyXsophistication

efficacyXsophistication %>% arrange(-efficacy) %>% kablebox()

eXsplot <- efficacyXsophistication %>% # filter(efficacy > 0) %>% #FIXME 
  ggplot() +
  aes(x = dictionary_terms, y = efficacy) + 
  geom_point(aes(y = 10131, x = 7705), color = "red", shape = 0, size = 3) +
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm") +
  labs(caption = str_c("Comments on Dodd-Frank Rules, N = ", nrow(efficacyXsophistication) %>% prettyNum(big.mark = ",")),
       y = "Lobbying Success\nn(Words From Comment\nAdded to Final Rule)",
       x = "Technical Terms in Comment",
       color = "") +
  theme(legend.position = "bottom")

eXsplot + 
  annotate(y = 10131, x = 7705, color = "red", geom = "text", label = "Comment & Marked-up Draft Rule,\nU.S. Chamber of Commerce et al.", vjust = .8, hjust = -0.05, size = 3.5)

eXsplot + 
  scale_x_log10() +
  scale_y_log10() + 
  annotate(y = 10131, x = 7705, color = "red", geom = "text", label = "Comment & Marked-up Draft Rule,\nU.S. Chamber of Commerce et al.", vjust = .8, hjust = 1.05, size = 3.5)

# color 
eXsplot + 
  annotate(y = 10131, x = 7705, color = "red", geom = "text", 
           label = "Comment & Marked-up Draft Rule,\nU.S. Chamber of Commerce et al.", 
           vjust = .8, hjust = -0.05, size = 3.5) + 
  aes(color = org) + labs(color = "")

eXsplot + 
  scale_x_log10() +
  scale_y_log10() + 
  aes(color = org)+ labs(color = "") + 
  annotate(y = 10131, x = 7705, color = "red", geom = "text", label = "Comment & Marked-up Draft Rule,\nU.S. Chamber of Commerce et al.", vjust = .8, hjust = 1.05, size = 3.5)

# legal citations
eXsplot <- efficacyXsophistication %>%  # filter(efficacy > 0) %>% #FIXME 
  ggplot() +
  aes(x = Total_Legal_Citations, y = efficacy) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm") +
  labs(caption = str_c("Comments on Dodd-Frank Rules, N = ", nrow(efficacyXsophistication) %>% prettyNum(big.mark = ",")),
       color = "",
       y = "Lobbying Success\nn(Words From Comment\nAdded to Final Rule)",
       x = "Legal Citations in Comment") + 
  geom_point(aes(x = 31, y = 10131), color = "red", shape = 0, size = 3)+
  theme(legend.position = "bottom")


eXsplot  + 
  annotate(x = 31, y = 10131, color = "red", geom = "text", label = "Comment & Marked-up Draft Rule,\nU.S. Chamber of Commerce et al.", vjust = .8, hjust = -0.05, size = 3.5)

eXsplot + 
  scale_x_log10() +
  scale_y_log10() + 
  annotate(y = 10131, x = 31, color = "red", geom = "text", label = "Comment & Marked-up Draft Rule,\nU.S. Chamber of Commerce et al.", vjust = .5, hjust = 1.05, size = 3.5)

# color 
eXsplot  + 
  annotate(x = 31, y = 10131, color = "red", geom = "text", label = "Comment & Marked-up Draft Rule,\nU.S. Chamber of Commerce et al.", vjust = .8, hjust = -0.05, size = 3.5)  + aes(color = org) + labs(color = "")

eXsplot + 
  scale_x_log10() +
  scale_y_log10() + 
  aes(color = org) + labs(color = "") + 
  annotate(y = 10131, x = 31, color = "red", geom = "text", label = "Comment & Marked-up Draft Rule,\nU.S. Chamber of Commerce et al.", vjust = .8, hjust = 1.05, size = 3.5)
```

---
  
<!-- DO NOT MODIFY MAIN DATA (d) BELOW---> 

---

### Number of comments per agency

Technical terms measured for `r d %>% filter(comment_url %in% technical_terms$comment_url) %>% nrow()` of `r nrow(d)` comments.

```{r techical}
# matches
d %>% 
  count(Agency, name = "n comments matched with org") %>%
  left_join(
    d %>% 
      filter(comment_url %in% technical_terms$comment_url) %>% 
      count(Agency, name = "n with dictionary terms measured") 
    )  %>% 
  left_join(
    d %>% 
      dplyr::select(-efficacy) %>% 
      filter(comment_url %in% efficacy$comment_url) %>% 
      count(Agency, name = "n with efficacy measured")  
    )  %>% 
  kablebox()
```

---

# Plots

## Sophistication x assets

### Legal citations x assets

```{r assets-blue, fig.height=2.5, fig.width=3, out.width="50%"}
# assets-blue

b <- d %>% filter(!is.na(dictionary_terms))

b %>% dplyr::select(org_name, Total_Legal_Citations, org_resources, comment_url)  %>%  
  drop_na(org_name, org_resources) %>%
  kablebox()

# FDIC ASSETS 
# FDIC ASSETS 
p <- b %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`)) %>% 
  ggplot() +
  aes(x = `FDIC_Institutions-bestMatch:ASSET`, # %>% log(), 
      y = Total_Legal_Citations ) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Assets",
       y = "Legal Citations", 
       title = "FDIC-Insured Banks")

p

p + 
  scale_y_log10() +
  scale_x_log10()

# nonprofits
p <- b %>% 
  ggplot() +
  aes(x = assets, 
      y = Total_Legal_Citations) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  )+ 
  labs(x = "Assets",
       y = "Legal Citations",
       title = "Nonprofits")

p

p + 
  scale_y_log10() +
  scale_x_log10()

# contribution
p <- b %>% 
  ggplot() +
  aes(x = MeanContribAmount/1000, 
      y = Total_Legal_Citations) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Mean PAC Contribution ($1,000)",
       y = "Legal Citations",
       title = "Campaign Donors")

p

p + 
  scale_y_log10() +
  scale_x_log10()



p <- b %>% 
  #filter(marketcap2 > 1000000) %>% 
  ggplot() +
  aes(x = marketcap2/1000000000, 
      y = Total_Legal_Citations) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Market Capitalization (Billions)",
       y = "Legal Citations",
       title = "Publicly-Traded Companies")

p

p + 
  scale_y_log10() +
  scale_x_log10() + 
  xlim(c(0, 400))


# b %>% count(comment_agency, is.na( assets))

b %>% filter(Total_Legal_Citations>10,
             !is.na(org_name)) %>% dplyr::select(org_name,Total_Legal_Citations, comment_url, everything()) %>% arrange(-Total_Legal_Citations) %>% kablebox()
```

### Technical terms x assets

```{r assets-tech, fig.height=2.5, fig.width=3, out.width="50%"}
t <- d %>% drop_na(dictionary_terms)


# FDIC ASSETS 
p <- t %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`),
         `FDIC_Institutions-bestMatch:ASSET` > 10) %>% 
  ggplot() +
  aes(x = `FDIC_Institutions-bestMatch:ASSET`, # %>% log(), 
      y = dictionary_terms ) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Assets",
       y = "Technical Terms", 
       title = "FDIC-Insured Banks")

p 

p + 
  scale_y_log10() + 
  scale_x_log10()

t %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`),
         `FDIC_Institutions-bestMatch:ASSET` > 10,
         dictionary_terms == 0) %>%
  dplyr::select(org_name, everything() ) %>% 
  kablebox()

# nonprofits
p <- t %>% 
  filter(!is.na(assets),
         assets > 10) %>% 
  ggplot() +
  aes(x = assets, 
      y = dictionary_terms) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) +
  labs(x = "Assets",
       y = "Technical Terms",
       title = "Nonprofits")

p 

p

# p + 
#   scale_y_log10() +
#   scale_x_log10()

# contribution
p <- t %>% 
  filter(!is.na(MeanContribAmount)) %>%
  ggplot() +
  aes(x = MeanContribAmount/1000, 
      y = dictionary_terms) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) +
  labs(x = "Mean PAC Contribution ($1,000)",
       y = "Technical Terms",
       title = "Campaign Donors")

p

p + 
  scale_y_log10() +
  scale_x_log10()


p <- t %>% 
  filter(!is.na(marketcap2)) %>% 
  ggplot() +
  aes(x = marketcap2/1000000000, 
      y = dictionary_terms) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) +
  labs(x = "Market Capitalization (Billions)",
       y = "Technical Terms",
       title = "Publicly-Traded Companies")

p 

p + 
  scale_y_log10() +
  scale_x_log10() + 
  xlim(c(0, 400))
```

## Efficacy x assets


```{r assets-efficacy}
e <- d %>% drop_na(efficacy)


# FDIC ASSETS 
p <- e %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`)) %>% 
  ggplot() +
  aes(x = `FDIC_Institutions-bestMatch:ASSET`/1000, # %>% log(), 
      y = efficacy ) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Assets ($1,000)",
       y = "Words in Comment\nAdded to Final Rule", 
       title = "FDIC-Insured Banks")

p

p + 
  scale_y_log10() +
  scale_x_log10()


e %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`), efficacy == 0) %>%
  dplyr::select(org_name, everything() ) %>% 
  kablebox()

# nonprofits
p <- e %>% 
  filter(!is.na(assets)) %>% 
  ggplot() +
  aes(x = assets/1000, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Assets ($1,000)",
       y = "Words in Comment\nAdded to Final Rule", 
       title = "Nonprofits")

p

p + 
  scale_y_log10() +
  scale_x_log10()


# contribution
p <- e %>% 
  filter(!is.na(MeanContribAmount)) %>%
  ggplot() +
  aes(x = MeanContribAmount/1000, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Mean PAC Contribution ($1,000)",
       y = "Words in Comment\nAdded to Final Rule",
       title = "Campaign Donors")

p

p + 
  scale_y_log10() +
  scale_x_log10()

# market cap
p <- e %>% 
  filter(!is.na(marketcap2)) %>% 
  ggplot() +
  aes(x = marketcap2/1000000, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) +
  labs(x = "Market Capitalization ($1,000,000)",
       y = "Words in Comment\nAdded to Final Rule",
       title = "Publicly-traded Companies")

p

p + 
  scale_y_log10() +
  scale_x_log10()
```

## Efficacy x sophistication

```{r efficacy-bluebook}
p <- e %>% 
  ggplot() +
  aes(x = Total_Legal_Citations, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Legal Citations",
       y = "Words in Comment\nAdded to Final Rule") 

p

p + 
  scale_y_log10() +
  scale_x_log10()
```
  
```{r efficacy-terms}
p <- e %>% 
  #filter(!is.na(marketcap2)) %>% 
  ggplot() +
  aes(x = dictionary_terms, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Technical Terms",
       y = "Words in Comment\nAdded to Final Rule") 

p

p + 
  scale_y_log10() +
  scale_x_log10()
```

---

# Regressions

```{r coef_mapping, cache=FALSE}
# change knitr defaults 
knitr::opts_chunk$set(fig.show="show",
                      fig.height=1, 
                      fig.width=5, 
                      out.width = "80%")

```


## Sophistication

> NOTE: I'm using OLS for now but will switch to Poisson or Negative Binomial. 

### Bluebook

```{r}
b %>% drop_na(assets, Total_Legal_Citations) %>% 
  arrange(-Total_Legal_Citations) %>% 
  dplyr::select(assets, Total_Legal_Citations, comment_url) %>% 
  kablebox()

```


These models have the prefix `mb_`. The dependent variable is a count of technical terms per comment.


```{r mb}
rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Sophistication",
  `2` = "Sophistication",
  `3` = "Sophistication"
)

attr(rows, 'position') <- c(0)


mb_assets <- lm(Total_Legal_Citations ~ assets,  data = b  %>% mutate(assets = assets/10000000000))

mb_opensecrets <- glm(Total_Legal_Citations ~ MeanContribAmount,
           data = b %>% mutate(MeanContribAmount = MeanContribAmount/10000))

mb_marketcap <- glm(Total_Legal_Citations ~ marketcap2,
           data = b  %>% mutate(marketcap2 = marketcap2/10000000000))

models <- list(mb_assets, mb_opensecrets, mb_marketcap)

modelsummary(models)

modelplot(mb_opensecrets) + theme(legend.position = "none") +  
  labs(x = "Additional Legal Citations per Ten Thousand Dollars")

modelplot(mb_marketcap) + theme(legend.position = "none") +  
  labs(x = "Additional Legal Citations per Ten Billion Dollars")
```

### Technical Terms

These models have the prefix `mt_`. The dependent variable is a count of technical terms per comment.

```{r mt}
t %>% drop_na(assets, dictionary_terms) %>% 
  arrange(-dictionary_terms) %>% 
  dplyr::select(assets, dictionary_terms, comment_url) %>% 
  kablebox()

# broken out by org type 

mt_assets <- lm(dictionary_terms ~ assets,
           data = t  %>% mutate(assets = assets/10000000000))

mt_opensecrets <- glm(dictionary_terms ~ MeanContribAmount,
           data = t %>% mutate(MeanContribAmount = MeanContribAmount/10000))

mt_marketcap <- glm(dictionary_terms ~ marketcap2,
           data = t  %>% mutate(marketcap2 = marketcap2/10000000000))

models <- list(mt_assets, mt_marketcap)

# FIXME 
# modelsummary(models)

modelplot( mt_opensecrets) + theme(legend.position = "none") +  
  labs(x = "Additional Technical Terms per Ten Thousand Dollars")

modelplot(mt_marketcap) + theme(legend.position = "none") + 
  labs(x = "Additional Technical Terms per Ten Billion Dollars")
```

---

## Efficacy

### Efficacy by Assets 

These models have the prefix `me_`. The dependent variable is the efficacy score.

```{r mea}
# broken out by org type 

mea_assets <- lm(efficacy ~ assets,
           data = e  %>% mutate(assets = assets/1000000))

mea_opensecrets <- glm(efficacy ~ MeanContribAmount,
           data = e %>% mutate(MeanContribAmount = MeanContribAmount/1000))

mea_marketcap <- glm(efficacy ~ marketcap2,
           data = e  %>% mutate(marketcap2 = marketcap2/1000000))

models <- list(mea_assets, mea_opensecrets, mea_marketcap)

# FIXME 
#modelsummary(models)

modelplot( mea_assets) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Million Dollars")

modelplot( mea_opensecrets) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Thousand Dollars")

modelplot(mea_marketcap) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Million Dollars")
```



### Efficacy by Sophistication  

These models have the prefix `mes_`. The dependent variable is the efficacy score.

```{r mes}
mes_bluebook <- lm(efficacy ~ Total_Legal_Citations,
           data = d )

mes_terms <- glm(efficacy ~ dictionary_terms,
           data = d)

mes_terms_bluebook <- glm(efficacy ~ dictionary_terms + Total_Legal_Citations,
           data = d )

models <- list(mes_terms , mes_bluebook , mes_terms_bluebook )

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Efficacy",
   `2` = "Efficacy",
  `3` = "Efficacy"
)

attr(rows, 'position') <- c(0)


# FIXME 
# modelsummary(models)#, gof_map = gm)

modelplot(mes_terms) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Technical Term")

modelplot( mes_bluebook ) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Legal Citation")

modelplot(mes_terms_bluebook ) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule")

modelplot(models) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule")
```


---

## Efficacy by Assets Mediated by Sophistication

To assess sophistication as a mediator between wealth and the influence of public comments on rules (efficacy), we estimate the average conditional marginal effect (ACME, conditional on the number of technical terms or legal citations) and average direct effect (ADE) of wealth using mediation analysis. 


These models have the prefix `mem_`. The dependent variable is the efficacy score. The mediator is technical terms.

### Assets x legal citations
```{r mediation-assets-bluebook, fig.width=4, fig.height=3}
library(mediation)

b$org_type %>% unique


# model predicting mediator, sophistication 
model.m <- lm(Total_Legal_Citations ~ assets * org_type,  
              data = b  %>% mutate(assets = assets/10000000000) %>% 
                drop_na(Total_Legal_Citations, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ Total_Legal_Citations + assets * org_type,  
               data = b  %>% mutate(assets = assets/10000000000))

models <- list(model.m, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Legal Citations",
   `2` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m, model.y, sims=1000, treat = "assets",
mediator = "Total_Legal_Citations")

summary(med.cont)

plot(med.cont, main = "Legal Citations as a Mediator Between\nAssets and Lobbying Success", 
     xlab = "Words From Comment Added to Final Rule")
#modelplot(med.cont) + labs()
```

### Assets x technical terms
```{r mediation-assets-terms, fig.width=4, fig.height=3}
# model predicting mediator, sophistication 
model.m <- lm(dictionary_terms ~ assets,  
              data = b  %>% mutate(assets = assets/10000000000) %>% 
                drop_na(dictionary_terms, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ dictionary_terms + assets,  
               data = b  %>% mutate(assets = assets/10000000000))

models <- list(model.m, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Technical Terms",
   `2` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m, model.y, sims=1000, treat = "assets",
mediator = "dictionary_terms")

summary(med.cont)

plot(med.cont, 
     main = "Technical Terms as a Mediator Between\nAssets and Lobbying Success",       
     xlab = "Words from Comment Added to Final Rule")
```

### Market cap x legal citations
```{r mediation-marketcap-bluebook, fig.width=4, fig.height=3}
# model predicting mediator, sophistication 
model.m <- lm(Total_Legal_Citations ~ marketcap2,  
              data = b  %>% mutate(marketcap2 = marketcap2/10000000000) %>% 
                drop_na(Total_Legal_Citations, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ Total_Legal_Citations + marketcap2,  
               data = b  %>% mutate(assets = marketcap2/10000000000))

models <- list(model.m, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Legal Citations",
   `2` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m, model.y, sims=1000, treat = "marketcap2",
mediator = "Total_Legal_Citations")

summary(med.cont)

plot(med.cont, 
     main = "Legal Citations as a Mediator Between\nAssets and Lobbying Success",       
     xlab = "Words from Comment Added to Final Rule")
```


### Market cap x technical terms 
```{r mediation-marketcap-terms, fig.width=4, fig.height=3}
# model predicting mediator, sophistication 
model.m <- lm(dictionary_terms ~ marketcap2,  
              data = b  %>% mutate(marketcap2 = marketcap2/10000000000) %>% 
                drop_na(dictionary_terms, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ dictionary_terms + marketcap2,  
               data = b  %>% mutate(marketcap2 = marketcap2/10000000000))

models <- list(model.m, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Technical Terms",
   `2` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m, model.y, sims=1000, treat = "marketcap2",
mediator = "dictionary_terms")

summary(med.cont)

plot(med.cont, 
     main = "Technical Terms as a Mediator Between\nAssets and Lobbying Success",     
     xlab = "Words from Comment Added to Final Rule")
```

### Market cap x technical terms  x legal citations 

```{r mediation-marketcap-terms-bluebook, fig.width=4, fig.height=3}
# model predicting mediator, sophistication 
model.m1 <- lm(dictionary_terms ~ marketcap2,  
              data = b  %>% mutate(marketcap2 = marketcap2/10000000000) %>% 
                drop_na(dictionary_terms, efficacy))

model.m2 <- lm(Total_Legal_Citations ~ marketcap2,  
              data = b  %>% mutate(marketcap2 = marketcap2/10000000000) %>% 
                drop_na(Total_Legal_Citations, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ dictionary_terms + Total_Legal_Citations +  marketcap2,  
               data = b  %>% mutate(marketcap2 = marketcap2/10000000000))

models <- list(model.m1, model.m2, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Technical Terms",
    `2` = "Legal Citations",
   `3` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m1, model.y, sims=1000, treat = "marketcap2",
mediator = "dictionary_terms")

summary(med.cont)

plot(med.cont, main = "Technical Terms as a Mediator Between\nAssets and Lobbying Success",       
     xlab = "Words from Comment Added to Final Rule")

med.cont <- mediate(model.m2, model.y, sims=1000, treat = "marketcap2",
mediator = "Total_Legal_Citations")

summary(med.cont)

plot(med.cont, main = "Legal Citations as a Mediator Between\nAssets and Lobbying Success",       
     xlab = "Words from Comment Added to Final Rule")

#FI
# modelsummary::modelsummary(med.cont)
```

# Save data 

```{r save}
n_comments <- nrow(efficacyXsophistication)

save(n_comments,
     efficacyXsophistication, 
     file = here::here("data", "efficacyXsophistication.Rdata"))
```

# TODO


## Presentation 

- [ ] Predicted probability plots for all models presented in the paper. These should replace all tables. All tables should appear in the appendix. 

- [ ] Nonprofit and credit union plots for the correlation between assets and sophistication

- [ ] `assets-tech-` figures should have x-axis scales in the millions or billions 

## Analysis 

- [ ] split out FDIC banks and nonprofits in asset mediation analysis? (at the moment, neither type of asset is correlated with efficacy, so mediation analysis is a low priority)

## Data

- [ ] check on the status of OCC comments (missing from the attachments table as of May 2022)

- [ ] Try to get efficacy measures for key observations. For example, in cases where we have market cap: 

Observations for which we have market cap and sophistication but are missing efficacy measures (POSSIBLY DUE TO THERE BEING NO FINAL RULE): 

```{r}
b %>% drop_na(marketcap, Total_Legal_Citations) %>% 
  arrange(-Total_Legal_Citations) %>% 
  filter(is.na(efficacy)) %>% 
  dplyr::select(efficacy,marketcap, Total_Legal_Citations, org_name, comment_url) %>% 
  kablebox()
```
