---
title: "Efficacy in Financial Rulemaking"
#subtitle: "Appendix and Replication Code"
output:
    bookdown::html_document2:
      highlight: zenburn
      toc: true
      toc_float: true
      code_folding: hide
      number_sections: false
---



```{r options, include=FALSE}
# rmarkdown::render("docs/efficacy.Rmd")

## Sets defaults for R chunks
knitr::opts_chunk$set(#echo = FALSE, # echo = TRUE means that code will show
                      cache = FALSE,
                      #cache = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      fig.show="hold",
                      fig.pos= "htbp",
                      fig.path = "../figs/", # figs folder at root (up one from /docs)
                      fig.align='center',
                      fig.cap = '   ',
                      fig.retina = 1, #6, #FIXME for publication quality images
                      fig.height=2.5, 
                      fig.width=3, 
                      out.width="50%",
                      # out.width = "100%",
                      out.extra = "")

library("xaringan")
library("xaringanthemer")
library("here")
library("modelsummary")

library(scales)
library(magrittr)
# library(broom)
library(here)
library(knitr)
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)
#library(mediation)
#library(lme4)
#library(lmerTest)
#library(fixest)
#library(modelsummary)
library(tidyverse)

# table defaults
modelsummary <- function(...) modelsummary::modelsummary(..., 
                                                         stars = T, 
                                                         add_rows = rows,
                                                         coef_rename = cm,
                                                         coef_omit = "(Intercept)"#, gof_map = gm
                                                         ) %>% 
  row_spec(row = 1, bold = T)

# coeficient plot defaults
modelplot <- function(...) modelsummary::modelplot(..., 
                                                   coef_omit = "(Intercept)",
                                                   coef_rename = cm) + 
  geom_vline(xintercept = 0, 
             linetype = 2, 
             alpha = .5) + 
  aes(shape = model) 

style_mono_light(base_color = "#3b444b",
          link_color = "#B7E4CF",
          #background_color = "#FAF0E6", # linen
          header_font_google = google_font("PT Sans"), 
          text_font_google = google_font("Old Standard"), 
          text_font_size = "18px",
          padding = "10px",
          code_font_google = google_font("Inconsolata"), 
          code_inline_background_color    = "#F5F5F5", 
          table_row_even_background_color = "#ddede5",
          extra_css = 
            list(".remark-slide-number" = list("display" = "none")))
```

```{r setup}
options(scipen=999)

# source(here::here("code", "setup.R"))

# defaults for plots
library(ggplot2); theme_set(theme_minimal());
options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_color_discrete <- function(...){
  scale_color_viridis_d(..., direction = -1, 
                        begin = 0, end = .6, option = "viridis")}
scale_fill_discrete <- function(...){
  scale_fill_viridis_d(..., direction = -1, 
                       begin = 0, end = .6, option = "viridis")}

scale_color_continuous <- function(...){
  scale_color_viridis_c(..., direction = -1, 
                        option = "viridis")}
scale_fill_continuous <- function(...){
  scale_fill_viridis_c(..., direction = -1, 
                       option = "viridis")}

# Table formatting
library(kableExtra)
kablebox <- . %>% 
  slice_head(n = 300) %>%
  knitr::kable() %>% 
  kable_styling() %>% 
  scroll_box(height = "400px")
```

# Data

The root for this script is `finreg`. Most of the data are in `finreg/data` (some in a subfolder `merged_resources`). Others are up one level in `FINREGRULEMAKE2/Data`. This can and should be streamlined significantly. 


## Sophistication 

File: `Data/Dictionary_Terms.RData` contains six objects (3 sets of measures for both comments and attachments)

### 1. Dictionary counts of technical terms used in comments and attachments

Objects: `technical_terms_comments` and `technical_terms_attachment`

Variables:

- `doc_id` - the comment_url or attachment_url in the comments and attachments files in master.sqlite
- `uk_law` - UK law terms - this is in the file as I was curious how many of the terms would be in a UK law dictionary.
- `banking` - US banking terms in Merriam Webster's banking dictionary
- `us_law` - US law terms in Merriam Webster's US law dictionary. We didn't use Black's law dictionary because it's incomplete, as shown at the beginning of the `dictionary_and_bluebook.R` file
- `overlap` - terms in both banking and us_law
- `dictionary_term`s - banking + us_law - overlap
- `Comment` - 1 if from the comments file in Master, 0 if from attachments

### 2. Tables and Figures

Counts of Tables and Figures. Looks at the maximum number of tables, with large jumps excluded. For example, a document with tables 1, 2, 3, and 99 would treat 99 as an error and say there were three tables. This mostly comes from bad OCRing or documents that have footnotes in between the word "table" and the table number.

Objects: `Tables_and_Figures_attachments` and `Tables_and_Figures_comments`

Variables:

- `comment_url` - the comment_url or attachment_url in the comments and attachments files in master.sqlite
- `Figures` - counts of figures
- `Tables`- counts of tables
- `Comment` - 1 if from comments, 0 if from attachments
- `Visualizations` - sum of figures + tables

### 3. Bluebook legal citations

Counts of citations to US code, Supreme Court cases, appellate and district court cases, the code of federal regulations, and the federal register

Objects: `bluebok_comments` and `bluebook_attachments`

Variables:

- `Comment` - 1 if from comments, 0 if from attachments
- `comment_url` - the comment_url or attachment_url in the comments and attachments files in master.sqlite
- `US_Code` - counts of US code citations
- `Supreme_Court_Cases` - counts of Supreme Court cases
- `Appeals_and_District_Court_Cases` - counts of citations to Appeals and district court cases
- `Code_of_Federal_Regulations` - counts of citations to CFR
- `Federal_Register_Total` - counts of citations to federal register
- `Total_Legal_Citations` - sum of above except comment dummy


```{r sophistication}
# sophistication 
load(here("data", "Dictionary_Terms.Rdata")  %>% str_remove("finreg")  )

# drop duplicates 
technical_terms_comments %<>% 
  distinct() 

technical_terms_attachments %<>% 
  distinct() 

bluebook_comments %<>% 
  distinct() 

bluebook_attachments %<>% 
  distinct()  
```


```{r sophistication-join}
# summarize and merge term counts from comment text boxes and attachments
# max <- . %>% base::max(na.rm = TRUE)


# sum by comment url 
#FIXME, why are these not unique! 
bluebook_c <- bluebook_comments %>% 
  drop_na(Total_Legal_Citations) %>% 
  group_by(comment_url) %>% 
  dplyr::select(-comment) %>% 
  summarise_all(base::max)

# whereas these should not be uniqe to comment url 
bluebook_a <- bluebook_attachments %>% 
  drop_na(Total_Legal_Citations) %>% 
  group_by(comment_url) %>% 
  dplyr::select(-comment) %>% 
  summarise_all(base::max)

# join both and max again 
bluebook <- full_join(bluebook_a,
                      bluebook_c) %>% 
  group_by(comment_url) %>% 
  summarise_all(base::max)

# # check for unique comment_url
# bluebook %>% count(comment_url, sort = T)

# sum by comment url 
#FIXME, why are these not unique!? 
technical_terms_c <- technical_terms_comments %>% 
  drop_na(dictionary_terms) %>% 
  group_by(comment_url) %>% 
  dplyr::select(-comment) %>% 
  summarise_all(base::max)

# whereas these should not be uniqe to comment url 
technical_terms_a <- technical_terms_attachments %>% 
  drop_na(dictionary_terms) %>% 
  group_by(comment_url) %>% 
  dplyr::select(-comment) %>% 
  summarise_all(base::max)

# join both and sum again 
technical_terms <- full_join(technical_terms_a,
                             technical_terms_c) %>% 
  group_by(comment_url) %>% 
  summarise_all(base::max)

# # check for unique comment_url
# technical_terms %>% count(comment_url, sort = T)

full_join(technical_terms, bluebook) %>% kablebox()

# check that they are the same 
# full_join(bluebook, technical_terms)
```

---

## Assets 

- see https://judgelord.github.io/finreg/participation

```{r asset-data}
load(here::here("data", "commenter_assets.Rdata"))

d <- commenter_assets

#FIXME MOVE TO TOP 
d$comment_url %<>% str_replace("document\\?D=", "comment/")


d %>% arrange(assets) %>% 
  dplyr::select(org_name, assets, revenue, comment_url) %>% kablebox()

d %>% arrange(marketcap2) %>% 
  dplyr::select(org_name, marketcap, comment_url) %>% kablebox()

d %>% arrange(-MeanContribAmount) %>% 
  dplyr::select(org_name, MeanContribAmount, comment_url) %>% kablebox()
```

---

## Efficacy

File: `Data/attachment_efficacy_w_docket.csv.`

Variables: 

- `efficacy` = `cumulative_sequence_length_over_10`

Other efficacy measures that we are not using: 

- number_of_other_sequences_over_10
- number_of_other_sequences_over_25
- number_of_other_sequences_over_50
- number_of_other_sequences_over_100
- cumulative_sequence_length_over_10
- cumulative_sequence_length_over_25
- cumulative_sequence_length_over_50
- cumulative_sequence_length_over_100
- longest_sequence_length
- longest_repeated_text

```{r efficacy}
# efficacy
efficacy_raw <- read_csv( here::here("data", "new_attachment_efficacy_w_docket.csv")  %>% str_remove("finreg")  )

# inspect 
# efficacy_raw %>% distinct() %>% dplyr::select(attachment_url, fr_document_id_final) %>% add_count(attachment_url) %>% arrange(-n) %>%   kablebox()

# # look for non-numeric values other than headers
# efficacy_raw %>% 
#   filter(!is.na(cumulative_sequence_length_over_10),
#          comment_url != "comment_url") %>% 
#   mutate(efficacy = cumulative_sequence_length_over_10 %>% as.numeric() ) %>% 
#   filter(is.na(efficacy)) %>% 
#   dplyr::select(comment_url, cumulative_sequence_length_over_10)

# select needed vars. url is comment url (even for attachments)
efficacy <- efficacy_raw %>% 
  # make comment url 
  mutate(comment_url2 = attachment_url %>% 
           str_replace("https://downloads.regulations.gov/", 
                       "https://www.regulations.gov/comment/" ) %>% 
           str_remove("/attachment_.*"),
         comment_url = coalesce(comment_url, comment_url2),
         efficacy = cumulative_sequence_length_over_10 %>% as.numeric()
         ) %>% 
  dplyr::select(comment_url,
         efficacy) %>% 
  distinct() 

# check for OCC comments (missing as of May 2022)
# efficacy %>% filter(str_detect(comment_url, "OCC"))

# check for CFPB comments (not missing, but failing to merge with d on URL?)
# efficacy %>% filter(str_detect(comment_url, "CFPB"))



efficacy %<>% drop_na(efficacy) 


# take max
efficacy %<>% 
  group_by(comment_url) %>% 
  summarise_all(base::max)

efficacy %>% arrange(-efficacy) %>% kablebox()

# d$comment_url %in% efficacy$comment_url %>% sum

# efficacy$comment_url %in% d$comment_url %>% sum

#efficacy %>% filter(str_detect(comment_url, "CFPB")) %>%  kablebox()

d  %<>% left_join(efficacy) 

d %>% group_by(Agency) %>% count(is.na(efficacy))
```



```{r testing, eval = FALSE}
# check number of NAs 
bluebook_comments %>%
  summarise_all(is.na) %>%
  summarise_all(sum)

# multiple per url? 
bluebook_comments %>%  count(comment_url, sort = T)

bluebook_attachments %>%  count(comment_url, sort = T)

# example
bluebook_attachments %>% filter(comment_url == "https://www.regulations.gov/comment/OCC-2011-0008-0126") %>% kablebox()

bluebook_comments %>% filter(comment_url == "https://www.regulations.gov/comment/OCC-2011-0008-0126") %>% kablebox()

technical_terms_comments %>% count(comment_url, sort = T)

technical_terms_attachments %>% count(comment_url, sort = T)
```

---

### Join sophistication and asset data

```{r sophistication-assets-join}
# Join 
d %<>% 
  left_join(bluebook %>% dplyr::select(comment_url, Total_Legal_Citations)) %>% 
  left_join(technical_terms %>% dplyr::select(comment_url, dictionary_terms)) 

d %>% 
  dplyr::select(comment_url, org_name, Total_Legal_Citations, dictionary_terms, assets, marketcap, MeanContribAmount) %>% 
  filter(!is.na(dictionary_terms)) %>% 
  kablebox()

# write out missing comment urls
d %>% 
  filter(is.na(dictionary_terms)) %>% dplyr::select(comment_url) %>% write_csv(file = "dictionary_terms_missing.csv")

# FIXME Missing as of May 2022
# bluebook %>% filter(str_detect(comment_url, "CFPB-2019-0021-0406"))
# technical_terms %>% filter(str_detect(comment_url, "CFPB-2019-0021-0406"))
```

---

<!-- DO NOT MODIFY MAIN DATA (d) BELOW---> 

---

### number of comments per agency

Technical terms measured for `r d %>% filter(comment_url %in% technical_terms$comment_url) %>% nrow()` of `r nrow(d)` comments.

```{r techical}
# matches
d %>% 
  count(Agency, name = "n comments matched with org") %>%
  left_join(
    d %>% 
      filter(comment_url %in% technical_terms$comment_url) %>% 
      count(Agency, name = "n with dictionary terms measured") 
    )  %>% 
  left_join(
    d %>% 
      dplyr::select(-efficacy) %>% 
      filter(comment_url %in% efficacy$comment_url) %>% 
      count(Agency, name = "n with efficacy measured")  
    )  %>% 
  kablebox()
```

---

# Plots

## Sophistication x assets

### Legal citations x assets

```{r assets-blue, fig.height=2.5, fig.width=3, out.width="50%"}
# assets-blue

b <- d %>% filter(!is.na(dictionary_terms))

b %>% dplyr::select(org_name, Total_Legal_Citations, org_resources, comment_url)  %>%  
  drop_na(org_name, org_resources) %>%
  kablebox()

# FDIC ASSTS 
# FDIC ASSTS 
p <- b %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`)) %>% 
  ggplot() +
  aes(x = `FDIC_Institutions-bestMatch:ASSET`, # %>% log(), 
      y = Total_Legal_Citations ) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Assets",
       y = "Legal Citations", 
       title = "FDIC-Insured Banks")

p

p + 
  scale_y_log10() +
  scale_x_log10()

# nonprofits
p <- b %>% 
  ggplot() +
  aes(x = assets, 
      y = Total_Legal_Citations) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  )+ 
  labs(x = "Assets",
       y = "Legal Citations",
       title = "Nonprofits")

p

p + 
  scale_y_log10() +
  scale_x_log10()

# contribution
p <- b %>% 
  ggplot() +
  aes(x = MeanContribAmount, 
      y = Total_Legal_Citations) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Average PAC Contribution",
       y = "Legal Citations",
       title = "Campaign Donors")

p

p + 
  scale_y_log10() +
  scale_x_log10()



p <- b %>% 
  #filter(marketcap2 > 1000000) %>% 
  ggplot() +
  aes(x = marketcap2/1000000000, 
      y = Total_Legal_Citations) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Market Capitalization (Billions)",
       y = "Legal Citations",
       title = "Publicly-Traded Companies")

p

p + 
  scale_y_log10() +
  scale_x_log10() + 
  xlim(c(0, 400))


# b %>% count(comment_agency, is.na( assets))

b %>% filter(Total_Legal_Citations>10,
             !is.na(org_name)) %>% dplyr::select(org_name,Total_Legal_Citations, comment_url, everything()) %>% arrange(-Total_Legal_Citations) %>% kablebox()
```

### Technical terms x assets

```{r assets-tech, fig.height=2.5, fig.width=3, out.width="50%"}
t <- d %>% drop_na(dictionary_terms)


# FDIC ASSTS 
p <- t %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`)) %>% 
  ggplot() +
  aes(x = `FDIC_Institutions-bestMatch:ASSET`, # %>% log(), 
      y = dictionary_terms ) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Assets",
       y = "Technical Terms", 
       title = "FDIC-Insured Banks")

p 

p + 
  scale_y_log10() + 
  scale_x_log10()

t %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`), dictionary_terms == 0) %>%
  dplyr::select(org_name, everything() ) %>% 
  kablebox()

# nonprofits
p <- t %>% 
  filter(!is.na(assets)) %>% 
  ggplot() +
  aes(x = assets, 
      y = dictionary_terms) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) +
  labs(x = "Assets",
       y = "Technical Terms",
       title = "Nonprofits")

p 

p + 
  scale_y_log10() +
  scale_x_log10()

# contribution
p <- t %>% 
  filter(!is.na(MeanContribAmount)) %>%
  ggplot() +
  aes(x = MeanContribAmount, 
      y = dictionary_terms) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) +
  labs(x = "Average PAC Contribution",
       y = "Technical Terms",
       title = "Campaign Donors")

p

p + 
  scale_y_log10() +
  scale_x_log10()


p <- t %>% 
  filter(!is.na(marketcap2)) %>% 
  ggplot() +
  aes(x = marketcap2/1000000000, 
      y = dictionary_terms) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) +
  labs(x = "Market Capitalization (Billions)",
       y = "Technical Terms",
       title = "Publicly-Traded Companies")

p 

p + 
  scale_y_log10() +
  scale_x_log10() + 
  xlim(c(0, 400))
```

## Efficacy x assets


```{r assets-efficacy}
e <- d %>% drop_na(efficacy)


# FDIC ASSTS 
p <- e %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`)) %>% 
  ggplot() +
  aes(x = `FDIC_Institutions-bestMatch:ASSET`, # %>% log(), 
      y = efficacy ) + 
  geom_point(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Assets",
       y = "Number of Words in Comment\nAdded to Final Rule", 
       title = "FDIC-Insured Banks")

p

p + 
  scale_y_log10() +
  scale_x_log10()


e %>% 
  filter(!is.na(`FDIC_Institutions-bestMatch:ASSET`), efficacy == 0) %>%
  dplyr::select(org_name, everything() ) %>% 
  kablebox()

# nonprofits
p <- e %>% 
  filter(!is.na(assets)) %>% 
  ggplot() +
  aes(x = assets, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Assets",
       y = "Number of Words in Comment\nAdded to Final Rule", 
       title = "Nonprofits")

p

p + 
  scale_y_log10() +
  scale_x_log10()


# contribution
p <- e %>% 
  filter(!is.na(MeanContribAmount)) %>%
  ggplot() +
  aes(x = MeanContribAmount, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Average PAC Contribution",
       y = "Words in Comment\nAdded to Final Rule",
       title = "Campaign Donors")

p

p + 
  scale_y_log10() +
  scale_x_log10()

# market cap
p <- e %>% 
  filter(!is.na(marketcap2)) %>% 
  ggplot() +
  aes(x = marketcap2, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) +
  labs(x = "Market Capitalization",
       y = "Number of Words in Comment\nAdded to Final Rule",
       title = "Publicly-traded Companies")

p

p + 
  scale_y_log10() +
  scale_x_log10()
```

## Efficacy x sophistication

```{r efficacy-bluebook}
p <- e %>% 
  ggplot() +
  aes(x = Total_Legal_Citations, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Legal Citations",
       y = "Number of Words in Comment\nAdded to Final Rule") 

p

p + 
  scale_y_log10() +
  scale_x_log10()
```
  
```{r efficacy-terms}
p <- e %>% 
  #filter(!is.na(marketcap2)) %>% 
  ggplot() +
  aes(x = dictionary_terms, 
      y = efficacy) + 
  geom_jitter(alpha = .5) + 
  geom_smooth(method = "lm"
  ) + 
  labs(x = "Technical Terms",
       y = "Number of Words in Comment\nAdded to Final Rule") 

p

p + 
  scale_y_log10() +
  scale_x_log10()
```

---

# Regressions

```{r coef_mapping, cache=FALSE}
# change knitr defaults 
knitr::opts_chunk$set(fig.show="show",
                      fig.height=1, 
                      fig.width=5, 
                      out.width = "80%")

# rename coeficients for tables and plots 
cm = c("ASSET" = "Assets",
       "ASSETS" = "Assets (Hundreds of Millions)",
       "Assets" = "Assets (Billions)",
       "assets" = "Assets",
       "marketcap2" = "Market Capitalization",
       "Class SM" = "State Bank",
       "Class SB" = "Savings Bank",
       "Class SA" = "Savings Association",
       "Class NM" = "Commercial Bank",
       "ASSETS:Class SM" = "Assets x State Bank",
       "ASSETS:Class SB" = "Assets x Savings Bank",
       "ASSETS:Class SA" = "Assets x Savings Association",
       "ASSETS:Class NM" = "Assets x Commercial Bank",
       "dictionary_terms" = "Technical Terms",
       "Total_Legal_Citations" = "Legal Citations")

gm = list("Num.Obs." = "Number of Comments",
       "R2" = "R2",
       "AIC" = "AIC")
```


## Sophistication

> NOTE: I'm using OLS for now but will switch to Poisson or Negative Binomial. 

### Bluebook

```{r}
b %>% drop_na(assets, Total_Legal_Citations) %>% 
  arrange(-Total_Legal_Citations) %>% 
  dplyr::select(assets, Total_Legal_Citations, comment_url) %>% 
  kablebox()

```


These models have the prefix `mb_`. The dependent variable is a count of technical terms per comment.


```{r mb}
rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Sophistication",
  `2` = "Sophistication",
  `3` = "Sophistication"
)

attr(rows, 'position') <- c(0)


mb_assets <- lm(Total_Legal_Citations ~ assets,  data = b  %>% mutate(assets = assets/10000000000))

mb_opensecrets <- glm(Total_Legal_Citations ~ MeanContribAmount,
           data = b %>% mutate(MeanContribAmount = MeanContribAmount/10000))

mb_marketcap <- glm(Total_Legal_Citations ~ marketcap2,
           data = b  %>% mutate(marketcap2 = marketcap2/10000000000))

models <- list(mb_assets, mb_opensecrets, mb_marketcap)

modelsummary(models)

modelplot(mb_opensecrets) + theme(legend.position = "none") +  
  labs(x = "Additional Legal Citations per Ten Thousand Dollars")

modelplot(mb_marketcap) + theme(legend.position = "none") +  
  labs(x = "Additional Legal Citations per Ten Billion Dollars")
```

### Technical Terms

These models have the prefix `mt_`. The dependent variable is a count of technical terms per comment.

```{r mt}
t %>% drop_na(assets, dictionary_terms) %>% 
  arrange(-dictionary_terms) %>% 
  dplyr::select(assets, dictionary_terms, comment_url) %>% 
  kablebox()

# broken out by org type 

mt_assets <- lm(dictionary_terms ~ assets,
           data = t  %>% mutate(assets = assets/10000000000))

mt_opensecrets <- glm(dictionary_terms ~ MeanContribAmount,
           data = t %>% mutate(MeanContribAmount = MeanContribAmount/10000))

mt_marketcap <- glm(dictionary_terms ~ marketcap2,
           data = t  %>% mutate(marketcap2 = marketcap2/10000000000))

models <- list(mt_assets, mt_marketcap)

# FIXME 
# modelsummary(models)

modelplot( mt_opensecrets) + theme(legend.position = "none") +  
  labs(x = "Additional Technical Terms per Ten Thousand Dollars")

modelplot(mt_marketcap) + theme(legend.position = "none") + 
  labs(x = "Additional Technical Terms per Ten Billion Dollars")
```

---

## Efficacy

### Efficacy by Assets 

These models have the prefix `me_`. The dependent variable is the efficacy score.

```{r mea}
# broken out by org type 

mea_assets <- lm(efficacy ~ assets,
           data = e  %>% mutate(assets = assets/1000000))

mea_opensecrets <- glm(efficacy ~ MeanContribAmount,
           data = e %>% mutate(MeanContribAmount = MeanContribAmount/1000))

mea_marketcap <- glm(efficacy ~ marketcap2,
           data = e  %>% mutate(marketcap2 = marketcap2/1000000))

models <- list(mea_assets, mea_opensecrets, mea_marketcap)

# FIXME 
#modelsummary(models)

modelplot( mea_assets) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Million Dollars")

modelplot( mea_opensecrets) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Thousand Dollars")

modelplot(mea_marketcap) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Million Dollars")
```



### Efficacy by Sophistication  

These models have the prefix `mes_`. The dependent variable is the efficacy score.

```{r mes}
mes_bluebook <- lm(efficacy ~ Total_Legal_Citations,
           data = d )

mes_terms <- glm(efficacy ~ dictionary_terms,
           data = d)

mes_terms_bluebook <- glm(efficacy ~ dictionary_terms + Total_Legal_Citations,
           data = d )

models <- list(mes_terms , mes_bluebook , mes_terms_bluebook )

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Efficacy",
   `2` = "Efficacy",
  `3` = "Efficacy"
)

attr(rows, 'position') <- c(0)


# FIXME 
# modelsummary(models)#, gof_map = gm)

modelplot(mes_terms) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Technical Term")

modelplot( mes_bluebook ) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule per Legal Citation")

modelplot(mes_terms_bluebook ) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule")

modelplot(models) + theme(legend.position = "none") +  
  labs(x = "Words Added to Final Rule")
```


---

## Efficacy by Assets Mediated by Sophistication

To assess sophistication as a mediator between wealth and the influence of public comments on rules (efficacy), we estimate the average conditional marginal effect (ACME, conditional on the number of technical terms or legal citations) and average direct effect (ADE) of wealth using mediation analysis. 


These models have the prefix `mem_`. The dependent variable is the efficacy score. The mediator is technical terms.

### Assets x legal citations
```{r mediation-assets-bluebook, fig.width=4, fig.height=3}
library(mediation)


# model predicting mediator, sophistication 
model.m <- lm(Total_Legal_Citations ~ assets,  
              data = b  %>% mutate(assets = assets/10000000000) %>% 
                drop_na(Total_Legal_Citations, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ Total_Legal_Citations + assets,  
               data = b  %>% mutate(assets = assets/10000000000))

models <- list(model.m, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Legal Citations",
   `2` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m, model.y, sims=1000, treat = "assets",
mediator = "Total_Legal_Citations")

summary(med.cont)

plot(med.cont)#, main = "Legal Citations as a Mediator of Assets")
#modelplot(med.cont) + labs()
```

### Assets x technical terms
```{r mediation-assets-terms, fig.width=4, fig.height=3}
# model predicting mediator, sophistication 
model.m <- lm(dictionary_terms ~ assets,  
              data = b  %>% mutate(assets = assets/10000000000) %>% 
                drop_na(dictionary_terms, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ dictionary_terms + assets,  
               data = b  %>% mutate(assets = assets/10000000000))

models <- list(model.m, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Technical Terms",
   `2` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m, model.y, sims=1000, treat = "assets",
mediator = "dictionary_terms")

summary(med.cont)

plot(med.cont)#, main = "Technical Terms as a Mediator of Assets")
```

### Market cap x legal citations
```{r mediation-marketcap-bluebook, fig.width=5, fig.height=4}
# model predicting mediator, sophistication 
model.m <- lm(Total_Legal_Citations ~ marketcap2,  
              data = b  %>% mutate(marketcap2 = marketcap2/10000000000) %>% 
                drop_na(Total_Legal_Citations, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ Total_Legal_Citations + marketcap2,  
               data = b  %>% mutate(assets = marketcap2/10000000000))

models <- list(model.m, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Legal Citations",
   `2` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m, model.y, sims=1000, treat = "marketcap2",
mediator = "Total_Legal_Citations")

summary(med.cont)

plot(med.cont)#, main = "Legal Citations")
```


### Market cap x technical terms 
```{r mediation-marketcap-terms, fig.width=4, fig.height=3}
# model predicting mediator, sophistication 
model.m <- lm(dictionary_terms ~ marketcap2,  
              data = b  %>% mutate(marketcap2 = marketcap2/10000000000) %>% 
                drop_na(dictionary_terms, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ dictionary_terms + marketcap2,  
               data = b  %>% mutate(marketcap2 = marketcap2/10000000000))

models <- list(model.m, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Technical Terms",
   `2` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m, model.y, sims=1000, treat = "marketcap2",
mediator = "dictionary_terms")

summary(med.cont)

plot(med.cont)#, main = "Techical Terms as a Mediator")
```

### Market cap x technical terms  x legal citations 

```{r mediation-marketcap-terms-bluebook, fig.width=4, fig.height=3}
# model predicting mediator, sophistication 
model.m1 <- lm(dictionary_terms ~ marketcap2,  
              data = b  %>% mutate(marketcap2 = marketcap2/10000000000) %>% 
                drop_na(dictionary_terms, efficacy))

model.m2 <- lm(Total_Legal_Citations ~ marketcap2,  
              data = b  %>% mutate(marketcap2 = marketcap2/10000000000) %>% 
                drop_na(Total_Legal_Citations, efficacy))

# model predicting DV
model.y <- glm(efficacy ~ dictionary_terms + Total_Legal_Citations +  marketcap2,  
               data = b  %>% mutate(marketcap2 = marketcap2/10000000000))

models <- list(model.m1, model.m2, model.y)

rows <- tibble(
  term = c("Dependent Variable"),
  `1` = "Technical Terms",
    `2` = "Legal Citations",
   `3` = "Efficacy",
)

attr(rows, 'position') <- c(0)


modelsummary(models)

med.cont <- mediate(model.m1, model.y, sims=1000, treat = "marketcap2",
mediator = "dictionary_terms")

summary(med.cont)

plot(med.cont)

med.cont <- mediate(model.m2, model.y, sims=1000, treat = "marketcap2",
mediator = "Total_Legal_Citations")

summary(med.cont)

plot(med.cont)

#FI
# modelsummary::modelsummary(med.cont)
```

# TODO

- [ ] check on the status of OCC comments (missing from the attachments table as of May 2022)

- [ ] split out FDIC banks and nonprofits in asset mediation analysis? (at the moment, neither type of asset is correlated with efficacy, so mediation analysis is a low priority)

- [ ] Try to get efficacy measures for key observations. For example, in cases where we have market cap: 

Observations for which we have market cap and sophistication but are missing efficacy measures: 

```{r}
b %>% drop_na(marketcap, Total_Legal_Citations) %>% 
  arrange(-Total_Legal_Citations) %>% 
  filter(is.na(efficacy)) %>% 
  dplyr::select(efficacy,marketcap, Total_Legal_Citations, org_name, comment_url) %>% 
  kablebox()
```
